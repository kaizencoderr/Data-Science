{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Freund_Tyler_Lab 4: Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GTO2KMti07__",
        "YAnuY8Sv1DoO",
        "ZlDfGvy61EMS",
        "1foS74O01FfP",
        "2rFY8D4Q1GsZ",
        "Aw1fJ59W0_t3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xxMXNDF7ckw"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# DMA Fall 21\n",
        "\n",
        "**Note** : This entire lab will be manually evaluated.\n",
        "\n",
        "Name : 'Tyler Freund'\n",
        "Collaborator : ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyb_RNpFreOr"
      },
      "source": [
        "# Lab 4: Neural Networks #\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj9Uh79ereOs"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6SRFrhfreOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "8cc50622-60df-4354-b68d-75699f4af6b9"
      },
      "source": [
        "!wget http://askoski.berkeley.edu/~zp/lab_4_training.csv\n",
        "!wget http://askoski.berkeley.edu/~zp/lab_4_test.csv\n",
        "\n",
        "df_train = pd.read_csv('./lab_4_training.csv')\n",
        "df_test = pd.read_csv('./lab_4_test.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 18:18:56--  http://askoski.berkeley.edu/~zp/lab_4_training.csv\n",
            "Resolving askoski.berkeley.edu (askoski.berkeley.edu)... 169.229.192.179\n",
            "Connecting to askoski.berkeley.edu (askoski.berkeley.edu)|169.229.192.179|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79177 (77K) [text/csv]\n",
            "Saving to: ‘lab_4_training.csv.12’\n",
            "\n",
            "lab_4_training.csv. 100%[===================>]  77.32K   491KB/s    in 0.2s    \n",
            "\n",
            "2021-09-22 18:18:57 (491 KB/s) - ‘lab_4_training.csv.12’ saved [79177/79177]\n",
            "\n",
            "--2021-09-22 18:18:57--  http://askoski.berkeley.edu/~zp/lab_4_test.csv\n",
            "Resolving askoski.berkeley.edu (askoski.berkeley.edu)... 169.229.192.179\n",
            "Connecting to askoski.berkeley.edu (askoski.berkeley.edu)|169.229.192.179|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26519 (26K) [text/csv]\n",
            "Saving to: ‘lab_4_test.csv.12’\n",
            "\n",
            "lab_4_test.csv.12   100%[===================>]  25.90K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-09-22 18:18:57 (1.57 MB/s) - ‘lab_4_test.csv.12’ saved [26519/26519]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>year</th>\n",
              "      <th>eyecolor</th>\n",
              "      <th>height</th>\n",
              "      <th>miles</th>\n",
              "      <th>brothers</th>\n",
              "      <th>sisters</th>\n",
              "      <th>computertime</th>\n",
              "      <th>exercise</th>\n",
              "      <th>exercisehours</th>\n",
              "      <th>musiccds</th>\n",
              "      <th>playgames</th>\n",
              "      <th>watchtv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>577</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>third</td>\n",
              "      <td>hazel</td>\n",
              "      <td>72.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>677</td>\n",
              "      <td>male</td>\n",
              "      <td>19</td>\n",
              "      <td>second</td>\n",
              "      <td>hazel</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1738</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>second</td>\n",
              "      <td>brown</td>\n",
              "      <td>63.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4.5</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1355</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>third</td>\n",
              "      <td>green</td>\n",
              "      <td>78.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>891</td>\n",
              "      <td>female</td>\n",
              "      <td>19</td>\n",
              "      <td>second</td>\n",
              "      <td>green</td>\n",
              "      <td>67.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  gender  age    year  ... exercisehours  musiccds  playgames  watchtv\n",
              "0         577    male   20   third  ...           0.0     100.0       10.0     10.0\n",
              "1         677    male   19  second  ...           9.0      70.0        3.0      5.0\n",
              "2        1738    male   20  second  ...           4.5      15.0        4.0     13.0\n",
              "3        1355    male   20   third  ...           9.0      20.0       10.0     10.0\n",
              "4         891  female   19  second  ...           2.0     164.0        0.0      2.0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGt_10ZAreOv"
      },
      "source": [
        "***\n",
        "### Question 1###\n",
        "Calculate a baseline accuracy measure using the majority class, assuming a target variable of 'gender'. The majority class is the most common value of the target variable in a particular dataset. Accuracy is calculated as (true positives + true negatives) / (all negatives and positives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZPiLgekreOw"
      },
      "source": [
        "**Question 1.a**  \n",
        "Find the majority class in the training set. If you always predicted this class in the training set, what would your accuracy be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYjEFc1greOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2626c18f-1c4b-446d-b9a4-1b52e2249bc6"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "num_male = df_train.loc[df_train['gender'] == \"male\"]\n",
        "num_male = len(num_male)\n",
        "num_female = df_train.loc[df_train['gender'] == \"female\"]\n",
        "num_female = len(num_female)\n",
        "\n",
        "baseline_accuracy = num_female/(num_female+num_male)\n",
        "baseline_accuracy"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5427852348993288"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtvFM-hM0y2o"
      },
      "source": [
        "###ANSWER: 0.5427852348993288"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULPKW0IvreOy"
      },
      "source": [
        "**Question 1.b**   \n",
        "If you always predicted this same class (majority from the training set) in the test set, what would your accuracy be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfU5mwh405vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd9a836-dca7-45ee-b9f1-bda1b9e51a7c"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "num_male = df_test.loc[df_test['gender'] == \"male\"]\n",
        "num_male = len(num_male)\n",
        "num_female = df_test.loc[df_test['gender'] == \"female\"]\n",
        "num_female = len(num_female)\n",
        "\n",
        "baseline_accuracy = num_female/(num_female+num_male)\n",
        "baseline_accuracy"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5226130653266332"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pINRUJxG05v4"
      },
      "source": [
        "###ANSWER: 0.5226130653266332\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKb2Ju-GreO0"
      },
      "source": [
        "***\n",
        "### Question 2 ###\n",
        "Get started with Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYI6e3F3reO0"
      },
      "source": [
        "   \n",
        "Choose a NN implementation (eg: scikit-learn) and specify which you choose. Be sure the implementation allows you to modify the number of hidden layers and hidden nodes per layer.  \n",
        "\n",
        "NOTE: When possible, specify the logsig (sigmoid/logistc) function as the transfer function (another word for activation function) and use Levenberg-Marquardt backpropagation (lbfgs). It is possible to specify logistic in Sklearn MLPclassifier (Neural net).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4am3sGc4reO1"
      },
      "source": [
        "**Question 2.a**   \n",
        "Train a neural network with a single 10 node hidden layer. Only use the Height feature of the dataset to predict the Gender. You will have to change Gender to a 0 and 1 class. After training, use your trained model to predict the class using the height feature from the training set. What was the accuracy of this prediction?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbAzltaw067l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ee324b-16ed-4acd-ca6d-f4b524ff6a68"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df_train['gender'].replace({'female': 0, 'male': 1},inplace=True)\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=100, \n",
        "                    activation= 'logistic', solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X1 = df_train['height'].to_numpy()\n",
        "X_train = np.reshape(X1, (-1, 1))\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_train = clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training---\n",
            "0.7676174496644296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuaCk0l0067q"
      },
      "source": [
        "###ANSWER: 0.7676174496644296"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkqzIeshreO2"
      },
      "source": [
        "**Question 2.b**  \n",
        "Take the trained model from question 2.a and use it to predict the test set. This can be accomplished by taking the trained model and giving it the Height feature values from the test set. What is the accuracy of this model on the test set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw25ezWp07hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5e14cd-ba1b-4aa0-9bb4-d5f7680f7bdb"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df_test['gender'].replace({'female': 0, 'male': 1},inplace=True)\n",
        "\n",
        "X2 = df_test['height'].to_numpy()\n",
        "X_test = np.reshape(X2, (-1, 1))\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))\n",
        "\n"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test---\n",
            "0.7311557788944724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbHMAFvw07hm"
      },
      "source": [
        "###ANSWER: 0.7311557788944724"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMmIfsNEreO3"
      },
      "source": [
        "**Question 2.c**   \n",
        "Neural Networks tend to prefer smaller, normalized feature values. Try taking the log of the height feature in both training and testing sets or use a Standard Scalar operation in SKlearn to centre and normalize the data between 0-1 for continuous values. Repeat question 2.a and 2.b with the log version or the normalized and centered version of this feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDhCZPaU07_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9a3344-f39b-42bd-a162-cd942bca4372"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df_train['log_height'] = np.log(df_train['height'])\n",
        "df_test['log_height'] = np.log(df_test['height'])\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=100,\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X1 = df_train['log_height'].to_numpy()\n",
        "X_train = np.reshape(X1, (-1, 1))\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X2 = df_test['log_height'].to_numpy()\n",
        "X_test = np.reshape(X2, (-1, 1))\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.8439597315436241\n",
            "Accuracy on test---\n",
            "0.8542713567839196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTO2KMti07__"
      },
      "source": [
        "###ANSWER: \n",
        "Accuracy on train---\n",
        "0.8439597315436241\n",
        "Accuracy on test---\n",
        "0.8542713567839196"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_SlOdcarePC"
      },
      "source": [
        "***\n",
        "\n",
        "### Question 3###\n",
        "The rest of features in this dataset barring a few are categorical. No ML method accepts categorical features, so transform year, eyecolor, exercise into a set of binary features, one feature per unique original feature value, and mark the binary feature as ‘1’ if the feature value matches the original value and ‘0’ otherwise. Using only these binary variable transformed features, train and predict the class of the test set. What was your accuracy using Neural Network with a single 10 node hidden layer? During training, use a maximum number of iterations of 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjhzBFNV1Aip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e859f71-476a-4df0-939e-079902f5e171"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "dum_train = pd.get_dummies(df_train)\n",
        "dum_test = pd.get_dummies(df_test)\n",
        "\n",
        "dum_train = dum_train.iloc[:, 13:]\n",
        "dum_test = dum_test.iloc[:, 13:]\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, activation= 'logistic',\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:].to_numpy()\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.5713087248322147\n",
            "Accuracy on test---\n",
            "0.5527638190954773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyQ1EvAY1Ait"
      },
      "source": [
        "###ANSWER: \n",
        "Accuracy on train---\n",
        "0.5713087248322147\n",
        "Accuracy on test---\n",
        "0.5527638190954773"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSSr9sBlrePG"
      },
      "source": [
        "***\n",
        "### Question 4###\n",
        "Using a NN, report the accuracy on  the test set of a model that trained only on the height and the eye color features of instances in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMNSlOmJrePG"
      },
      "source": [
        "**Question 4.a**  \n",
        "What is the accuracy on the test set using the original height values (no pre-processing) and eye color as a one-hot?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_vN4tyv1Ckq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bc9d537-8216-4cd8-f4b0-c0cf5279340d"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "dum_test = dum_test.iloc[:, 5:10]\n",
        "dum_train = dum_train.iloc[:, 5:10]\n",
        "\n",
        "dum_train['height'] = df_train['height']\n",
        "dum_test['height'] = df_test['height']\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, activation= 'logistic',\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:].to_numpy()\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.5696308724832215\n",
            "Accuracy on test---\n",
            "0.5527638190954773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaL2o0TW1Cks"
      },
      "source": [
        "###ANSWER: \n",
        "Accuracy on test---\n",
        "0.5527638190954773"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC8Ipx9QrePH"
      },
      "source": [
        "**Question 4.b**  \n",
        "What is the accuracy on the test set using the log of height values (applied to both training and testing sets) and eye color as a one-hot?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFvzNv6O1DG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01296c25-6bfa-4acc-a068-befbf212635a"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "dum_train = pd.get_dummies(df_train)\n",
        "dum_test = pd.get_dummies(df_test)\n",
        "\n",
        "dum_train = dum_train.iloc[:, 13:]\n",
        "dum_test = dum_test.iloc[:, 13:]\n",
        "\n",
        "dum_test = dum_test.iloc[:, 5:10]\n",
        "dum_train = dum_train.iloc[:, 5:10]\n",
        "\n",
        "dum_train['height'] = df_train['height']\n",
        "dum_test['height'] = df_test['height']\n",
        "\n",
        "dum_train['height'] = np.log(df_train['height'])\n",
        "dum_test['height'] = np.log(df_test['height'])\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, activation= 'logistic',\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:].to_numpy()\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.8322147651006712\n",
            "Accuracy on test---\n",
            "0.8467336683417085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt3NMp1M1DG4"
      },
      "source": [
        "###ANSWER: \n",
        "Accuracy on test---\n",
        "0.8467336683417085"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYm2jqnprePI"
      },
      "source": [
        "**Question 4.c**  \n",
        "What is the accuracy on the test set using the Z-score of height values and eye color as a one-hot? \n",
        "\n",
        "Z-score is a normalization function. It is the value of a feature minus the average value for that feature (in the training set), divided by the standard deviation of that feature (in the training set). Remember that, whenever applying a function to a feature in the training set, it also has to be applied to that same feature in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mDjF6N1DoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1f3af0-ecfc-47cd-c463-35ecd0ba396d"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "dum_train = pd.get_dummies(df_train)\n",
        "dum_test = pd.get_dummies(df_test)\n",
        "\n",
        "dum_train = dum_train.iloc[:, 13:]\n",
        "dum_test = dum_test.iloc[:, 13:]\n",
        "\n",
        "dum_test = dum_test.iloc[:, 5:10]\n",
        "dum_train = dum_train.iloc[:, 5:10]\n",
        "\n",
        "dum_train['height'] = df_train['height']\n",
        "dum_test['height'] = df_test['height']\n",
        "\n",
        "sd_train = np.std(dum_train['height'])\n",
        "mean_train = np.mean(dum_train['height'])\n",
        "dum_train['height'] = (dum_train['height'] - mean_train) / sd_train\n",
        "\n",
        "sd_test = np.std(dum_test['height'])\n",
        "mean_test = np.mean(dum_test['height'])\n",
        "dum_test['height'] = (dum_test['height'] - mean_test) / sd_test\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, activation= 'logistic',\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:]\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.8473154362416108\n",
            "Accuracy on test---\n",
            "0.8668341708542714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAnuY8Sv1DoO"
      },
      "source": [
        "###ANSWER: \n",
        "Accuracy on test---\n",
        "0.8693467336683417"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh9qwu_9rePJ"
      },
      "source": [
        "***\n",
        "### Question 5 ###\n",
        "Repeat question 4 for exercise hours + eye color"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAgHz_r-1EMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85220d8-85bc-4b53-ce68-6ffcdadf3e00"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "dum_train = pd.get_dummies(df_train)\n",
        "dum_test = pd.get_dummies(df_test)\n",
        "\n",
        "dum_train = dum_train.loc[:, 'eyecolor_blue':'eyecolor_other']\n",
        "dum_test = dum_test.loc[:, 'eyecolor_blue':'eyecolor_other']\n",
        "\n",
        "dum_train['exer_hours'] = df_train['exercisehours']\n",
        "dum_test['exer_hours'] = df_test['exercisehours']\n",
        "\n",
        "#5a\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, activation= 'logistic',\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:].to_numpy()\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.5855704697986577\n",
            "Accuracy on test---\n",
            "0.5628140703517588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYGZ_l5NHLwV",
        "outputId": "ad3e90b5-3ef3-40b4-b11b-cdcc5710734e"
      },
      "source": [
        "#5b\n",
        "df_train = df_train[df_train.exercisehours != 0]\n",
        "df_test = df_test[df_test.exercisehours != 0]\n",
        "\n",
        "dum_train['exer_hours'] = np.log(df_train['exercisehours'])\n",
        "dum_test['exer_hours'] = np.log(df_test['exercisehours'])\n",
        "dum_train = dum_train.dropna(axis=0)\n",
        "dum_test = dum_test.dropna(axis=0)\n",
        "\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, activation= 'logistic',\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:].to_numpy()\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.5946666666666667\n",
            "Accuracy on test---\n",
            "0.5899581589958159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD4d6agRHS4A",
        "outputId": "73d7eb17-3b47-4ed1-a49a-cc0fe610442a"
      },
      "source": [
        "#5c\n",
        "dum_train = pd.get_dummies(df_train)\n",
        "dum_test = pd.get_dummies(df_test)\n",
        "\n",
        "dum_train = dum_train.loc[:, 'eyecolor_blue':'eyecolor_other']\n",
        "dum_test = dum_test.loc[:, 'eyecolor_blue':'eyecolor_other']\n",
        "\n",
        "dum_train['exer_hours'] = df_train['exercisehours']\n",
        "dum_test['exer_hours'] = df_test['exercisehours']\n",
        "\n",
        "sd_train = np.std(dum_train['exer_hours'])\n",
        "mean_train = np.mean(dum_train['exer_hours'])\n",
        "dum_train['exer_hours'] = (dum_train['exer_hours'] - mean_train) / sd_train\n",
        "\n",
        "sd_test = np.std(dum_test['exer_hours'])\n",
        "mean_test = np.mean(dum_test['exer_hours'])\n",
        "dum_test['exer_hours'] = (dum_test['exer_hours'] - mean_test) / sd_test\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), max_iter=50, activation= 'logistic',\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:].to_numpy()\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.6013333333333334\n",
            "Accuracy on test---\n",
            "0.5815899581589958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlDfGvy61EMS"
      },
      "source": [
        "###ANSWER: \n",
        "#5a:\n",
        "Accuracy on test---0.5628140703517588\n",
        "#5b:\n",
        "Accuracy on test---0.5899581589958159\n",
        "#5c:\n",
        "Accuracy on test---0.5815899581589958"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYVuaPWgrePL"
      },
      "source": [
        "***\n",
        "### Question 6###\n",
        "Combine the features from question 3, 4, and 5 (year, eyecolor, exercise, height, exercise hours). For numeric features use the best normalization method from questions 4 and 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iAiFhlFrePM"
      },
      "source": [
        "**Question 6.a**  \n",
        "What was the NN accuracy on the test set using the single 10 node hidden layer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuLJ6sTB1FfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae3081d-a3f3-49b0-af24-4df7787d6b80"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df_train = df_train[df_train.exercisehours != 0]\n",
        "df_test = df_test[df_test.exercisehours != 0]\n",
        "\n",
        "dum_train = pd.get_dummies(df_train)\n",
        "dum_test = pd.get_dummies(df_test)\n",
        "\n",
        "dum_train = dum_train.iloc[:, 13:]\n",
        "dum_test = dum_test.iloc[:, 13:]\n",
        "\n",
        "dum_train['height'] = df_train['height']\n",
        "dum_test['height'] = df_test['height']\n",
        "\n",
        "sd_train = np.std(dum_train['height'])\n",
        "mean_train = np.mean(dum_train['height'])\n",
        "dum_train['height'] = (dum_train['height'] - mean_train) / sd_train\n",
        "\n",
        "sd_test = np.std(dum_test['height'])\n",
        "mean_test = np.mean(dum_test['height'])\n",
        "dum_test['height'] = (dum_test['height'] - mean_test) / sd_test\n",
        "\n",
        "dum_train['exer_hours'] = np.log(df_train['exercisehours'])\n",
        "dum_test['exer_hours'] = np.log(df_test['exercisehours'])\n",
        "\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), activation= 'logistic',\n",
        "                 solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:].to_numpy()\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.8826666666666667\n",
            "Accuracy on test---\n",
            "0.7740585774058577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1foS74O01FfP"
      },
      "source": [
        "###ANSWER: \n",
        "Accuracy on test---0.7740585774058577"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jusc-kofrePP"
      },
      "source": [
        "***\n",
        "### Question 7- Bonus (10%)###\n",
        "Can you improve your test set prediction accuracy by 5% or more?  \n",
        "\n",
        "See how close to that milestone of improvement you can get by modifying the tuning parameters of  Neural Networks (the number of hidden layers, number of hidden nodes in each layer, the learning rate aka mu). A great guide to tuning parameters is explained in this guide: http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf. \n",
        "\n",
        "While the guide is specific to SVM and in particular the C and gamma parameters of the RBF kernel, the method applies to generally to any ML technique with tuning parameters.\n",
        "\n",
        "Please also write a paragraph in a markdown cell below with an explanation of your approach and evaluation metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvpoUdeq1GsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a09abf-64e2-47c6-b175-691552253979"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "df_train = df_train[df_train.exercisehours != 0]\n",
        "df_test = df_test[df_test.exercisehours != 0]\n",
        "\n",
        "dum_train = pd.get_dummies(df_train)\n",
        "dum_test = pd.get_dummies(df_test)\n",
        "\n",
        "dum_train = dum_train.iloc[:, 13:]\n",
        "dum_test = dum_test.iloc[:, 13:]\n",
        "\n",
        "dum_train['height'] = df_train['height']\n",
        "dum_test['height'] = df_test['height']\n",
        "\n",
        "sd_train = np.std(dum_train['height'])\n",
        "mean_train = np.mean(dum_train['height'])\n",
        "dum_train['height'] = (dum_train['height'] - mean_train) / sd_train\n",
        "\n",
        "sd_test = np.std(dum_test['height'])\n",
        "mean_test = np.mean(dum_test['height'])\n",
        "dum_test['height'] = (dum_test['height'] - mean_test) / sd_test\n",
        "\n",
        "dum_train['exer_hours'] = np.log(df_train['exercisehours'])\n",
        "dum_test['exer_hours'] = np.log(df_test['exercisehours'])\n",
        "\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(1000), activation= 'logistic', alpha=.01, batch_size= 5, learning_rate= 'adaptive',\n",
        "                    learning_rate_init= 10, power_t=1,  max_iter=100, beta_1= .1, beta_2=.5, solver='lbfgs', verbose=1,  random_state=1)\n",
        "\n",
        "X_train = dum_train[0:].to_numpy()\n",
        "\n",
        "Y_train = np.array(df_train['gender'])\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "print('Accuracy on train---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n",
        "\n",
        "X_test = dum_test[0:].to_numpy()\n",
        "\n",
        "Y_test = np.array(df_test['gender'])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on train---\n",
            "0.8386666666666667\n",
            "Accuracy on test---\n",
            "0.8368200836820083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rFY8D4Q1GsZ"
      },
      "source": [
        "###ANSWER: \n",
        "\n",
        "I was able to increase my accuracy score from question 6 by 6.2% (83.6%-77.4%=6.2%). I began my optimization by reading the documentation of the sklearn MLPclassifier and tried to familiaize myself with the parameters.  Next, I did some research as to which of these parameters could possibly lead me to a higher accuracy score; more specifically, whether I needed to increase or decrease these given parameters to better my accuracy score.  I proceeded to change each parameter one by one and seeing whether my output was moving closer or further from my goal.  The most significant impact I noticed on my output was when I changed my hidden layer size from 10 to 1000.  Although, I did see other changes in output when I tweaked the other parameters, none were as substantial as the hidden layer size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSYt4xMSvGxi"
      },
      "source": [
        ""
      ],
      "execution_count": 324,
      "outputs": []
    }
  ]
}