{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Freund_Tyler_Lab 6: Skip-grams",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDlU-kLCKDVZ"
      },
      "source": [
        "NAME = \"Tyler Freund\""
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW9zL4V6KDVc"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9a0ec075584699a44c46933457b0a8ba",
          "grade": false,
          "grade_id": "cell-a910b376742d04c0",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ECD5r2hFKDVd"
      },
      "source": [
        "# Lab 6: Skip Gram\n",
        "\n",
        "**Please read the following instructions very carefully**\n",
        "\n",
        "## Working on the assignment / FAQs\n",
        "- **Always use the seed/random_state as *42* wherever applicable** (This is to ensure repeatability in answers, across students and coding environments) \n",
        "- The type of question and the points they carry are indicated in each question cell\n",
        "- To avoid any ambiguity, each question also specifies what *value* must be set. Note that these are dummy values and not the answers\n",
        "- If an autograded question has multiple answers (due to differences in handling NaNs, zeros etc.), all answers will be considered.\n",
        "- You can delete the `raise NotImplementedError()`\n",
        "- **Submitting the assignment** : Download the '.ipynb' file from Colab and upload it to bcourses. Do not delete any outputs from cells before submitting.\n",
        "- That's about it. Happy coding!\n",
        "\n",
        "\n",
        "Available software:\n",
        " - Python's Gensim module: https://radimrehurek.com/gensim/ (install using pip)\n",
        " - Sklearn’s  TSNE module in case you use TSNE to reduce dimension (optional)\n",
        " - Python’s Matplotlib (optional)\n",
        "\n",
        "_Note: The most important hyper parameters of skip-gram/CBOW are vector size and windows size_\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a09a0bf3042da711c4bf843e9b4a4189",
          "grade": false,
          "grade_id": "cell-bf780e597c0216c8",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Vsocwry-KDVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "298ec335-81d1-4766-f4fe-73b33399440d"
      },
      "source": [
        "!pip install gensim\n",
        "!wget -nc https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz \n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import gensim\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "File ‘GoogleNews-vectors-negative300.bin.gz’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "47031c66b74746d23ccc5e8369446a4b",
          "grade": false,
          "grade_id": "cell-3f89500615a0096f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZF74G9bDKDVh"
      },
      "source": [
        "### **Q1 (1 point)** \n",
        "Find the cosine similarity between the following word pairs\n",
        "\n",
        "- (France, England)\n",
        "- (smaller, bigger)\n",
        "- (England, London)\n",
        "- (France, Rocket)\n",
        "- (big, bigger)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4d52dda406c3d8cd5e37d29755f0fb12",
          "grade": false,
          "grade_id": "cell-fbbe575f8f5a6368",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "SZD5ZaMvKDVk"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "from gensim.models import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "similarity_pair1 = model.similarity('France', 'England')\n",
        "similarity_pair2 = model.similarity('smaller', 'bigger')\n",
        "similarity_pair3 = model.similarity('England', 'London')\n",
        "similarity_pair4 = model.similarity('France', 'Rocket')\n",
        "similarity_pair5 = model.similarity('big', 'bigger')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "569aa8b664a41d901bf7b0a5e23e9930",
          "grade": true,
          "grade_id": "cell-929d59ed5d67f618",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "tFUPLSK7KDVp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5aebbd8a-ec7a-442a-e289-f9f9455eba37"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(similarity_pair1, similarity_pair2, similarity_pair3, similarity_pair4, similarity_pair5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.39804944 0.7302272 0.43992856 0.07114174 0.68423855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a7f270405ddf9ecbffde36e6c096b818",
          "grade": false,
          "grade_id": "cell-ccd6618b4fac3715",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "ZcqpWCjJKDVs"
      },
      "source": [
        "### **Q2 (1 point)** \n",
        "Write an expression to extract the vector representations of the words: \n",
        "\n",
        "- France\n",
        "- England\n",
        "- smaller\n",
        "- bigger\n",
        "- rocket\n",
        "- big\n",
        "\n",
        "Get only the first 5 elements for each vector representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "6b3cecb268eb9440c446cd3de984b7f6",
          "grade": false,
          "grade_id": "cell-00f3d05abb28aa23",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "6pzKlLyjKDVt"
      },
      "source": [
        "#Replace 0 with the code / value to get the first 5 elements of each vector; Do not delete this cell\n",
        "\n",
        "vector_1 = model['France'][0:5]\n",
        "vector_2 = model['England'][0:5]\n",
        "vector_3 = model['smaller'][0:5]\n",
        "vector_4 = model['bigger'][0:5]\n",
        "vector_5 = model['rocket'][0:5]\n",
        "vector_6 = model['big'][0:5]\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "401940f859774b3c1ec48338fa15682e",
          "grade": true,
          "grade_id": "cell-6f34229370fa873f",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "Hkj2ROGTKDVv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "085fa611-d1ae-433a-abb0-9f17604acd0f"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(vector_1)\n",
        "print(vector_2)\n",
        "print(vector_3)\n",
        "print(vector_4)\n",
        "print(vector_5)\n",
        "print(vector_6)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.04858398 0.07861328 0.32421875 0.03491211 0.07714844]\n",
            "[-0.19824219  0.11523438  0.0625     -0.05834961  0.2265625 ]\n",
            "[-0.05004883  0.03417969 -0.0703125   0.17578125  0.00689697]\n",
            "[-0.06542969 -0.09521484 -0.06225586  0.16210938  0.01989746]\n",
            "[-0.03198242  0.27148438 -0.2890625  -0.15429688  0.16894531]\n",
            "[ 0.11132812  0.10595703 -0.07373047  0.18847656  0.07666016]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ac8b42811c924e7988f17b9dbd3f71ef",
          "grade": false,
          "grade_id": "cell-4ad44071d3785409",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "2UBnMwiXKDVy"
      },
      "source": [
        "### **Q3 (1 point)** \n",
        "Find the euclidean distances between the word pairs : \n",
        "\n",
        "- (France, England)\n",
        "- (smaller, bigger)\n",
        "- (England, London)\n",
        "- (France, Rocket)\n",
        "- (big, bigger)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "a771483fbb59086604eb84bcc7c7f0ad",
          "grade": false,
          "grade_id": "cell-3aba86afc0ebd8a8",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "zQGd-YVoKDV3"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "def eu_dist_func(x_vec, y_vec):\n",
        "   summ = 0\n",
        "   for i in range(len(x_vec)):\n",
        "     summ += (x_vec[i] - y_vec[i])**2\n",
        "   return np.sqrt(summ)\n",
        "\n",
        "eu_dist1 = eu_dist_func(model['France'], model['England'])\n",
        "eu_dist2 = eu_dist_func(model['smaller'], model['bigger'])\n",
        "eu_dist3 = eu_dist_func(model['England'], model['London'])\n",
        "eu_dist4 = eu_dist_func(model['France'], model['Rocket'])\n",
        "eu_dist5 = eu_dist_func(model['big'], model['bigger'])\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "17796eb5de342e8f8e841aa137a2c41c",
          "grade": true,
          "grade_id": "cell-15ffa50b82de21ad",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "HsSg0l2UKDV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d84b8123-5a82-47cc-dfd4-71116a8ff9f6"
      },
      "source": [
        "#This is an autograded cell, do not edit / delete\n",
        "print(eu_dist1)\n",
        "print(eu_dist2)\n",
        "print(eu_dist3)\n",
        "print(eu_dist4)\n",
        "print(eu_dist5)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.015106670206923\n",
            "1.861874365812832\n",
            "2.8752836561510935\n",
            "3.892070952915602\n",
            "1.9586496085134812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "afc0e843c7545e2df83448feda9f28f5",
          "grade": false,
          "grade_id": "cell-7cd8b9b67386376d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "XvO2iU7QKDWA"
      },
      "source": [
        "### **Q4 (1 point)**\n",
        "Time to dabble with the power of Word2Vec. Find the 2 closest words  for the following conditions:  \n",
        "- (King - Man + Queen)\n",
        "- (bigger - big + small)\n",
        "- (waiting - wait + run)\n",
        "- (Texas + Milwaukee – Wisconsin)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "50ef096feb166865434fe2fca3d41f99",
          "grade": false,
          "grade_id": "cell-b72201968c5fd1ec",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "jCxWmA1eKDWB"
      },
      "source": [
        "#Replace 0 with the code / value; Do not delete this cell\n",
        "topmatches = model.most_similar(positive=['Queen', 'King'], negative=['Man'])\n",
        "closest1 = topmatches[0][0], topmatches[1][0]\n",
        "\n",
        "topmatches = model.most_similar(positive=['bigger', 'small'], negative=['big'])\n",
        "closest2 = topmatches[0][0], topmatches[1][0]\n",
        "\n",
        "topmatches = model.most_similar(positive=['waiting', 'run'], negative=['wait'])\n",
        "closest3 = topmatches[0][0], topmatches[1][0]\n",
        "\n",
        "topmatches = model.most_similar(positive=['Texas', 'Milwaukee'], negative=['Wisconsin'])\n",
        "closest4 = topmatches[0][0], topmatches[1][0]\n",
        "\n",
        "closest5 = 0\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f9c5ff502264f29d2632c6387f92686a",
          "grade": true,
          "grade_id": "cell-b69718ab0e1470bc",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "io9elfD8KDWE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b6fddddc-024b-444e-f814-cacb45476d94"
      },
      "source": [
        "#This is an autograded cell, do not edit/delete\n",
        "print(closest1)\n",
        "print(closest2)\n",
        "print(closest3)\n",
        "print(closest4)\n",
        "print(closest5)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Queen_Elizabeth', 'monarch')\n",
            "('larger', 'smaller')\n",
            "('running', 'runs')\n",
            "('Houston', 'Fort_Worth')\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "6432058d78f4fa52224c48a3b3e71d0d",
          "grade": false,
          "grade_id": "cell-73dca0e2072fef91",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "erUu4u71KDWJ"
      },
      "source": [
        "### **Q5 (3 points)**\n",
        "Using the vectors for the words in the Google News dataset, explore the semantic representation of these words through K-means clustering and explain your findings.\n",
        "\n",
        "*Note : Since there are ~3Mil words in the vocabulary, you can downsample it to ~20-30k randomly selected words*\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "7ecef46689f11d4d0a6fed72e049235f",
          "grade": true,
          "grade_id": "cell-80b177848b8b0212",
          "locked": false,
          "points": 3,
          "schema_version": 1,
          "solution": true
        },
        "id": "M3jN02fOKDWK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f0161d29-26d4-4a4d-fa00-1c45257148b3"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "import random\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "#Get random sample of words and extract corresponding vectors into array.\n",
        "all_words_list = list(model.wv.vocab)\n",
        "random.seed(42)\n",
        "sample_list = random.sample(all_words_list, 25000)\n",
        "vector_list = []\n",
        "sample_list\n",
        "for words in sample_list:\n",
        "  vector_list.append(model[words])\n",
        "\n",
        "#Explore when we make only 2 clusters.\n",
        "print(\" \")\n",
        "print(\"2 CLUSTERS\")\n",
        "X = vector_list\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans.fit(X)\n",
        "values = kmeans.labels_\n",
        "keys = sample_list\n",
        "cluster_dict = dict(zip(keys, values))\n",
        "\n",
        "print(\"--------First 100 Words in Cluster 1:----------\")\n",
        "n = 0\n",
        "for i in range(len(sample_list)):\n",
        "  if (cluster_dict[sample_list[i]] == 0) and n < 101:\n",
        "    print(sample_list[i])\n",
        "    n+=1\n",
        "\n",
        "print(\"---------First 100 Words in Cluster 2:---------\")\n",
        "n = 0\n",
        "for i in range(len(sample_list)):\n",
        "  if (cluster_dict[sample_list[i]] == 1) and n < 101:\n",
        "    print(sample_list[i])\n",
        "    n+=1\n",
        "\n",
        "#Explore when we make 20 clusters.\n",
        "print(\" \")\n",
        "print(\"20 CLUSTERS\")\n",
        "X = vector_list\n",
        "kmeans = KMeans(n_clusters=20, random_state=42)\n",
        "kmeans.fit(X)\n",
        "values = kmeans.labels_\n",
        "keys = sample_list\n",
        "cluster_dict = dict(zip(keys, values))\n",
        "\n",
        "clust_range = np.arange(0, 20, 1)\n",
        "for j in clust_range:\n",
        "  print(\"--------First 10 Words in Cluster:----------\")\n",
        "  print(j)\n",
        "  print(\" \")\n",
        "  n = 0\n",
        "  for i in range(len(sample_list)):\n",
        "    if (cluster_dict[sample_list[i]] == j) and n < 11:\n",
        "      print(sample_list[i])\n",
        "      n+=1\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "2 CLUSTERS\n",
            "--------First 100 Words in Cluster 1:----------\n",
            "Spokesman_Ramin_Mehmanparast\n",
            "Houthis\n",
            "Aloha_Airlines\n",
            "INVESTING_ACTIVITIES_Capital\n",
            "Ben_Matulino\n",
            "Carlos_Mamani\n",
            "wholly_owned_subsidiaries_Novatris\n",
            "########_Fax_+##\n",
            "automaker_Toyota_Motor\n",
            "Service_RxPG\n",
            "Mark_Mowers\n",
            "Enterprises_NASDAQ_CETV\n",
            "fever_cough_headache\n",
            "Audited_Results\n",
            "Napavalleyregister.com\n",
            "replaceable_battery\n",
            "Bureau_d'_Enquetes\n",
            "BOARD_OF_REVIEW\n",
            "Quiteh\n",
            "genomic_medicine\n",
            "By_Kristen_Zambo\n",
            "Roberto_Carlos_Magalhaes\n",
            "minister_Ayham_al\n",
            "AirPrime_MC####\n",
            "fried_onions\n",
            "Ted_Schlafke\n",
            "stent_thrombosis\n",
            "www.advaoptical.com\n",
            "Khalifa_Al_Thani\n",
            "ZEW_index\n",
            "Emre_Peker\n",
            "Manthan_Systems\n",
            "AsiaInfo_Holdings_NASDAQ\n",
            "malignant_plasma\n",
            "ABDULLAH\n",
            "SENATORS\n",
            "Crime_Victims_Compensation\n",
            "Ronnie_Bremer\n",
            "WARRI_Nigeria\n",
            "ESCONDIDO_Calif.\n",
            "Mary_MacElveen_Page\n",
            "michael_jackson\n",
            "bebe_outlet\n",
            "Legal_WebTV_Network\n",
            "skid\n",
            "MATTHEW_PENNINGTON\n",
            "Susan_Teri_Hatcher\n",
            "Acanthamoeba_keratitis_painful\n",
            "Allen_Lessels_covers\n",
            "arrows_machetes\n",
            "Pigeon_Detectives\n",
            "agent_Pini_Zahavi\n",
            "Particular_Concern\n",
            "Faruqi_LLP_Announces\n",
            "Iteamic\n",
            "Receives_Notice_From\n",
            "Torrontes\n",
            "adipex\n",
            "resident_Ronald_Garan\n",
            "Amulsar_gold\n",
            "Madaen\n",
            "Conditional_Use_Planned\n",
            "TM_ACCPAC\n",
            "für_das\n",
            "Delayed_Entry_Program\n",
            "hydrological_cycle\n",
            "Bob_Uecker\n",
            "Attribution\n",
            "ESPN_Buster_Olney\n",
            "H._Moskow\n",
            "Salesforce_CRM_http://www.salesforce.com/_applications\n",
            "Oliver_Hoyte\n",
            "Bemidji_Pioneer\n",
            "Cabinet_Secretary_Nobutaka\n",
            "avoidance_schemes\n",
            "pinch_hitter_Jeff_DaVanon\n",
            "gallium_nitride_GaN_wafers\n",
            "Haing_S._Ngor\n",
            "Temporary_Restraining_Order\n",
            "Moreton_Island\n",
            "By_GEOFF_JOHNSON\n",
            "numbness_tingling\n",
            "Student_Loan_Corp_STU\n",
            "de_Jesus_Cipitria\n",
            "Suspects_Caught\n",
            "warlord_Jean_Pierre\n",
            "Charisa_Coulter\n",
            "Mobilizes\n",
            "Randy_Tinseth\n",
            "Smallville_Episode\n",
            "compan_productivity_add\n",
            "subclinical_zinc_deficiency\n",
            "Jayson_Mellom\n",
            "N._Caudle\n",
            "VYTORIN\n",
            "transcranial_direct\n",
            "Iplicity\n",
            "destra\n",
            "Shami_Connelly\n",
            "www.lineagepower.com\n",
            "DEIRDRE_CONNER\n",
            "---------First 100 Words in Cluster 2:---------\n",
            "espresso_martinis\n",
            "wherefore\n",
            "HARD\n",
            "courtly_manners\n",
            "Hawai'ian\n",
            "Madhu_Chandra\n",
            "Sangtam\n",
            "audiovisual_presentations\n",
            "Abdul_Hakim_Eshaqzai\n",
            "Bori\n",
            "Girl_Hussler\n",
            "MiniMail\n",
            "Adarsh\n",
            "Devinder\n",
            "Drusch\n",
            "Casey_Rayborn_Hicks\n",
            "1B_Yonder_Alonso\n",
            "HSR_clearance\n",
            "PowerBand_™\n",
            "Parungao\n",
            "Hitachi_AMN####\n",
            "superintendent_Swati_Sathe\n",
            "Cienaga_de_Zapata\n",
            "Hillstone_Restaurant_Group\n",
            "Cyclone_Ami\n",
            "JACK_OSBOURNE\n",
            "actress_Radha_Mitchell\n",
            "Malcolm_Brinded_Shell\n",
            "Douglass\n",
            "Kampung_Acheh\n",
            "Phan_Van_Tu\n",
            "Herb_Boydstun\n",
            "Nelson_Mandela_Mother_Teresa\n",
            "bari\n",
            "Jason_Ringenberg\n",
            "holstered_weapon\n",
            "Jollie\n",
            "d'_origine\n",
            "Hearwell_Stadium\n",
            "Lansing_Mich._Charles_Babington\n",
            "IntercontinentalExchange_ICE.N_Quote_Profile\n",
            "Jim_Ozella\n",
            "symmetrical_triangle_pattern\n",
            "Senator_Omar_Hambagda\n",
            "Pjatkins\n",
            "Jane_Sauls\n",
            "Yesteryears_actress\n",
            "MAR_ECO_expedition\n",
            "Chuah\n",
            "Photographer_Captures\n",
            "follicly_challenged\n",
            "Fargoan\n",
            "TBP\n",
            "Quickdraw\n",
            "Scissors_Paper\n",
            "Joel_Robideaux\n",
            "DURHAM_NC_Chante_Black\n",
            "unlabeled_bottle\n",
            "Fraumeni\n",
            "ACLM\n",
            "Altium_Altium_Designer\n",
            "french_fry_grease\n",
            "Jan_Argonish\n",
            "AR_Drone_remote\n",
            "Linnie_Burton_Jr.\n",
            "Organic_Compound\n",
            "Glynis_Leyshon\n",
            "Idaho_CareLine\n",
            "Noyan_Tapan\n",
            "Shahpour\n",
            "Mhura\n",
            "Juon\n",
            "Ramsey_Baghdadi\n",
            "Rummble_Labs\n",
            "largely_unpatrolled_coastline\n",
            "Blue_Jackets_Activate\n",
            "Lake_Rhodhiss\n",
            "Muschler\n",
            "Legiant_Timecard\n",
            "Sandra_Jessee\n",
            "AC_Kleinheider\n",
            "Philips_VOIP###\n",
            "cardiac_anesthesiologist\n",
            "Paige_Poulos\n",
            "Susan_Romanyszyn\n",
            "Gadda_Da_Vida\n",
            "B_streptococcus\n",
            "owners_Bluegreen_Resorts\n",
            "Zirku\n",
            "stop_believin\n",
            "Cox_Bazar_Teknaf\n",
            "canola_rapeseed\n",
            "Penguin_Alexei_Kovalev\n",
            "Ferdi_Heyneke\n",
            "hurling_racial_epithets\n",
            "Delago\n",
            "Mrs_Oswal\n",
            "Ann_Temkin\n",
            "Hoblitzelle_Foundation\n",
            "Ted_Luciani\n",
            "Milwaukee_Admirals_AHL\n",
            " \n",
            "20 CLUSTERS\n",
            "--------First 10 Words in Cluster:----------\n",
            "0\n",
            " \n",
            "wherefore\n",
            "courtly_manners\n",
            "Nelson_Mandela_Mother_Teresa\n",
            "follicly_challenged\n",
            "hurling_racial_epithets\n",
            "maniacal_laughter\n",
            "flippant\n",
            "nasty\n",
            "Knee_jerk_reactions\n",
            "Khomeinist_regime\n",
            "protection_rackets\n",
            "--------First 10 Words in Cluster:----------\n",
            "1\n",
            " \n",
            "Hearwell_Stadium\n",
            "Mhura\n",
            "Trinny_Woodall\n",
            "Middlemount\n",
            "Pigeon_Detectives\n",
            "Clonegal\n",
            "Surridge\n",
            "avoidance_schemes\n",
            "Congupna\n",
            "Moreton_Island\n",
            "Cilcain\n",
            "--------First 10 Words in Cluster:----------\n",
            "2\n",
            " \n",
            "HARD\n",
            "BOARD_OF_REVIEW\n",
            "ABDULLAH\n",
            "SENATORS\n",
            "EWEN\n",
            "SEX_LIFE\n",
            "EVEN_AS\n",
            "AFFINITY\n",
            "SLIDE_SHOW\n",
            "MAKES_HIS_MARK\n",
            "YEAR-OLD\n",
            "--------First 10 Words in Cluster:----------\n",
            "3\n",
            " \n",
            "Hawai'ian\n",
            "unlabeled_bottle\n",
            "french_fry_grease\n",
            "fried_onions\n",
            "arrows_machetes\n",
            "holistic_healing\n",
            "sunken_battleship_USS\n",
            "Torrontes\n",
            "bustling_metropolis\n",
            "cleansers_moisturizers\n",
            "watery_soup\n",
            "--------First 10 Words in Cluster:----------\n",
            "4\n",
            " \n",
            "Drusch\n",
            "Parungao\n",
            "Douglass\n",
            "Jollie\n",
            "Fraumeni\n",
            "Muschler\n",
            "Delago\n",
            "Praegitzer\n",
            "Viette\n",
            "Magliulo\n",
            "Woitaszewski\n",
            "--------First 10 Words in Cluster:----------\n",
            "5\n",
            " \n",
            "Enterprises_NASDAQ_CETV\n",
            "Audited_Results\n",
            "ZEW_index\n",
            "AsiaInfo_Holdings_NASDAQ\n",
            "Ferdi_Heyneke\n",
            "Amulsar_gold\n",
            "CAD1\n",
            "LJM2_bought\n",
            "destra\n",
            "CNMIM\n",
            "Powershares_WilderHill_Clean\n",
            "--------First 10 Words in Cluster:----------\n",
            "6\n",
            " \n",
            "1B_Yonder_Alonso\n",
            "HSR_clearance\n",
            "PowerBand_™\n",
            "Hitachi_AMN####\n",
            "Hillstone_Restaurant_Group\n",
            "Herb_Boydstun\n",
            "d'_origine\n",
            "IntercontinentalExchange_ICE.N_Quote_Profile\n",
            "symmetrical_triangle_pattern\n",
            "fever_cough_headache\n",
            "Photographer_Captures\n",
            "--------First 10 Words in Cluster:----------\n",
            "7\n",
            " \n",
            "TBP\n",
            "genomic_medicine\n",
            "stent_thrombosis\n",
            "B_streptococcus\n",
            "Acanthamoeba_keratitis_painful\n",
            "adipex\n",
            "hydrological_cycle\n",
            "Ultrasounds\n",
            "BN#####\n",
            "numbness_tingling\n",
            "subclinical_zinc_deficiency\n",
            "--------First 10 Words in Cluster:----------\n",
            "8\n",
            " \n",
            "JACK_OSBOURNE\n",
            "actress_Radha_Mitchell\n",
            "Jason_Ringenberg\n",
            "Quickdraw\n",
            "Scissors_Paper\n",
            "Juon\n",
            "Gadda_Da_Vida\n",
            "stop_believin\n",
            "michael_jackson\n",
            "Susan_Teri_Hatcher\n",
            "Vowed\n",
            "--------First 10 Words in Cluster:----------\n",
            "9\n",
            " \n",
            "MiniMail\n",
            "replaceable_battery\n",
            "AirPrime_MC####\n",
            "storage\n",
            "2k\n",
            "Attribution\n",
            "workgroup_printers\n",
            "antimalware\n",
            "BIST\n",
            "HHR_SS\n",
            "DX##\n",
            "--------First 10 Words in Cluster:----------\n",
            "10\n",
            " \n",
            "Manthan_Systems\n",
            "Iteamic\n",
            "DialPad\n",
            "AbilityNet\n",
            "Iplicity\n",
            "SecureState\n",
            "Intuit_QuickBase\n",
            "HR_Payroll\n",
            "Magniflex\n",
            "Transition_Concierge\n",
            "Greenlight_Initiative\n",
            "--------First 10 Words in Cluster:----------\n",
            "11\n",
            " \n",
            "Spokesman_Ramin_Mehmanparast\n",
            "Houthis\n",
            "Aloha_Airlines\n",
            "Malcolm_Brinded_Shell\n",
            "automaker_Toyota_Motor\n",
            "Roberto_Carlos_Magalhaes\n",
            "minister_Ayham_al\n",
            "ESCONDIDO_Calif.\n",
            "agent_Pini_Zahavi\n",
            "resident_Ronald_Garan\n",
            "Madaen\n",
            "--------First 10 Words in Cluster:----------\n",
            "12\n",
            " \n",
            "Casey_Rayborn_Hicks\n",
            "Fargoan\n",
            "Joel_Robideaux\n",
            "Lake_Rhodhiss\n",
            "Crime_Victims_Compensation\n",
            "Boat_Shed\n",
            "groundbreaking_ceremony\n",
            "Princeton_Junction\n",
            "Audra_Caplan_president\n",
            "Rockaway_Borough\n",
            "Medical_Marijuana_Dispensary\n",
            "--------First 10 Words in Cluster:----------\n",
            "13\n",
            " \n",
            "holstered_weapon\n",
            "Jim_Ozella\n",
            "DURHAM_NC_Chante_Black\n",
            "Quiteh\n",
            "ACLM\n",
            "Ted_Schlafke\n",
            "Sandra_Jessee\n",
            "Penguin_Alexei_Kovalev\n",
            "Ronnie_Bremer\n",
            "Milwaukee_Admirals_AHL\n",
            "Bill_Pettingell\n",
            "--------First 10 Words in Cluster:----------\n",
            "14\n",
            " \n",
            "Napavalleyregister.com\n",
            "By_GEOFF_JOHNSON\n",
            "ten_articles\n",
            "LOZANO\n",
            "2Q_Earnings\n",
            "indulgent_Spa_Treatments_exclusively\n",
            "Every_Competitor\n",
            "Nancy_Knapp_Schilke\n",
            "Self_Regulatory_Organizations\n",
            "By_SANDY_COHEN\n",
            "rapidcityjournal.com\n",
            "--------First 10 Words in Cluster:----------\n",
            "15\n",
            " \n",
            "Bori\n",
            "Cyclone_Ami\n",
            "Phan_Van_Tu\n",
            "Senator_Omar_Hambagda\n",
            "Chuah\n",
            "Noyan_Tapan\n",
            "Khalifa_Al_Thani\n",
            "Sheikh_Jamaluddin\n",
            "El_Kanemi_Warriors\n",
            "phathi\n",
            "Montagnes\n",
            "--------First 10 Words in Cluster:----------\n",
            "16\n",
            " \n",
            "espresso_martinis\n",
            "audiovisual_presentations\n",
            "Abdul_Hakim_Eshaqzai\n",
            "Girl_Hussler\n",
            "superintendent_Swati_Sathe\n",
            "Cienaga_de_Zapata\n",
            "Kampung_Acheh\n",
            "Lansing_Mich._Charles_Babington\n",
            "Pjatkins\n",
            "Jane_Sauls\n",
            "Yesteryears_actress\n",
            "--------First 10 Words in Cluster:----------\n",
            "17\n",
            " \n",
            "Ben_Matulino\n",
            "Carlos_Mamani\n",
            "Mark_Mowers\n",
            "Bob_Uecker\n",
            "Oliver_Hoyte\n",
            "safety_Tyler_Sash\n",
            "Matt_Fornataro\n",
            "Mohammad_Aamer\n",
            "goalkeeper_Zeljko_Kalac\n",
            "fielder_Jayson_Werth\n",
            "Prefontaine_Classic\n",
            "--------First 10 Words in Cluster:----------\n",
            "18\n",
            " \n",
            "Madhu_Chandra\n",
            "Sangtam\n",
            "Adarsh\n",
            "Devinder\n",
            "bari\n",
            "Service_RxPG\n",
            "Narasaraopet\n",
            "Sarojini_Devi\n",
            "counsel_Abha_Rathore\n",
            "jatara\n",
            "Anand_Rai\n",
            "--------First 10 Words in Cluster:----------\n",
            "19\n",
            " \n",
            "INVESTING_ACTIVITIES_Capital\n",
            "wholly_owned_subsidiaries_Novatris\n",
            "########_Fax_+##\n",
            "By_Kristen_Zambo\n",
            "www.advaoptical.com\n",
            "Emre_Peker\n",
            "malignant_plasma\n",
            "WARRI_Nigeria\n",
            "Mary_MacElveen_Page\n",
            "Legal_WebTV_Network\n",
            "MATTHEW_PENNINGTON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KQPc2iHvusN"
      },
      "source": [
        "Kmeans clusters findings:\n",
        "When I used only 2 clusters (ie k = 2) it was hard to see a distinct pattern between the two clusters.  I think this is partly due to the fact that there is such a vast range of meaning in the words.  For instance, some are food, some are places, some are people, some are animals, some are items, etc.  However, when splitting with 20 clusters, I was able to see a much stronger pattern within each cluster.  More concretely, I observed that in cluster 4 of the k=20 model that there are 4 food/drink words within the list.  Similarly, in cluster 17 I noticed that nearly all of the words were people.  Furthermore, these people were almost all athletes/sports players.  Thus, by making more clusters I believe that the theme of the cluster became more transparent. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "0467b27a0f59504cbb62b851a002386f",
          "grade": false,
          "grade_id": "cell-5b2a5e8ff6c74323",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "rmdtLoHkKDWR"
      },
      "source": [
        "### **Q6 (1 point)**\n",
        "What loss function does the skipgram model use and briefly describe what this function is minimizing.\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "774aef2c5bf8ef9d92e3489d1cd80390",
          "grade": true,
          "grade_id": "cell-90cc4b2c0ae8e2c2",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "SyOASYXOKDWS"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# The Skipgram model uses a Cross Entropy categorical loss function.  Cross Entropy calculates the difference between two probability distributions; less\n",
        "# formally, it measures how far off the predicted probability is from the target (which is either 0 or 1)."
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "c14f6069f64cc86ab6e384d28df270d8",
          "grade": false,
          "grade_id": "cell-74a177caaabb5009",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "dbpuJx9CKDWV"
      },
      "source": [
        "### **Bonus Question (1 point)** \n",
        "Find at least 2 interesting word vec combinations like the ones given in Q4\n",
        "\n",
        "**Do not delete the below cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "c2d42b5327f4b020c7e1706506dd5ce9",
          "grade": true,
          "grade_id": "cell-7351297993d72e83",
          "locked": false,
          "points": 1,
          "schema_version": 1,
          "solution": true
        },
        "id": "pQM8C_T7KDWW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "09b9f41d-51bb-4002-e41b-3710446fa8ed"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "\n",
        "# (Dog + Kitten – Cat)\n",
        "topmatches = model.most_similar(positive=['Dog', 'Kitten'], negative=['Cat'])\n",
        "closest1_bonus = topmatches[0][0], topmatches[1][0]\n",
        "print(closest1_bonus)\n",
        "\n",
        "# (Dad + daughter – Mom)\n",
        "topmatches = model.most_similar(positive=['Dad', 'daughter'], negative=['Mom'])\n",
        "closest2_bonus = topmatches[0][0], topmatches[1][0]\n",
        "print(closest2_bonus)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Puppy', 'dog')\n",
            "('son', 'father')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe2aIT-YPn2X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}